## Context preparation

- Q, question
    - one
    - group by number, for example 3
        - only for calling api
    - group by category
        - _TODO_
    - all
    - manul input question
        - from CM:REPL to here
- P, paper
    - one
    - group by selection
    - all
- PT, template:
    - one per question
    - batch of question
- M, model
    - GPT
    - openLLM
        - _TODO_
    - langchain
    - other model

## Chat mode

- CM, chat mode
    - REPL when no question
    - auto run
- PC, Paper content
    - all content
    - map reduce
    - embedding/semantic search
    - refine mode
- PQ, Prompt question method
    - ask Q one by one
    - ask some Q in one request


## report format

- paper
- question_id
- question
- question_type
- human_answer
- AI_reply
- AI_answer
- correct_answer?
- AI_NA
- Comment
- explain
- correct_explain?
- sentences
- correct_sentences?
- confidence
- completion_tokens
- prompt_tokens
- total_tokens
- seconds
- model
- chat_mode
- date
- md5
- #batches
