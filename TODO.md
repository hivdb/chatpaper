## export report

- export result in an excel file
- report the token length of the documents we feed
- if the result csv file exist, ask if run from start

## Models support

- support MetaAI llama and Claude AI
- support Google API


## chat options

1. context + paper + all questions
    - check mapreduce and stuff RetriveQA method
2. use GPT3 only if possible
3. load local index with embedding
4. for specific questions with chain of thought method

## release

- markdown preparation code

## test

- w/wo cheatsheet
- w/wo embedding
- extract content about the question
- small text/sentence embedding
- group question by relationship
- simply, 3Q per request?
- categorize the paper
- contain table or not

### test parameters

- choose test set
- choose cheatsheet or not
- choose split question or not
- choose split content or not
- choose report or not
    - variation analysis
    - overall
- for section split content
    - test chuck overlap


## Title screening

- use title to know if the paper is related


## date file structure

- date file structure as an object


## Use fine-tune method to memorize the cheatsheet


## how many papers are bigger than context?


## mark question as the same

## Question consistancy check

- if plasma then active replication
- if naive then active replication
- if drug class contains then PI and INSTI
- if naive and no treated, should have number of individuals
- 4301 and 4302
- 4301 and 4101

## Check No but AI get NA


## Human x GPT-4 x Claude

if one of them get too much disagree in a paper.
May need recheck human results.
